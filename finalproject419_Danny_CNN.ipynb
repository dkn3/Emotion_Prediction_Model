{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#MFCC Extraction\n",
        "In this section of our notebook, we are preparing our data for the model. We start by defining a function to extract Mel-Frequency Cepstral Coefficients (MFCCs) from our BERSt audio files. MFCCs are a type of feature commonly used in audio and speech processing as they provide a compact representation of sound.\n",
        "\n",
        "Next, we process our data by loading the CSV files that contain information about the audio files and their labels. We construct the full paths for the chunk files, encode the 'affect' labels into integers, and then convert these integer labels into one-hot vectors. For each audio file, we extract the MFCCs and store them in a dictionary along with the corresponding one-hot vector.\n",
        "\n",
        "Finally, we save the MFCCs for the training and test data to .npy files. This allows us to load the MFCCs directly in future runs, saving the time and computational resources that would be required to extract the MFCCs again. This step is crucial for preparing our data for training all three of our models"
      ],
      "metadata": {
        "id": "zSOgWvIvYW9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "def extract_mfcc(file_path, n_fft, hop_length, max_sequence_length):\n",
        "    # Load the audio file\n",
        "    signal, sample_rate = librosa.load(file_path, sr=None)\n",
        "\n",
        "    # Normalize the signal\n",
        "    signal = librosa.util.normalize(signal)\n",
        "\n",
        "    # Extract MFCC features\n",
        "    mfcc = librosa.feature.mfcc(y=signal,\n",
        "                                sr=sample_rate,\n",
        "                                n_fft=n_fft,\n",
        "                                hop_length=hop_length,\n",
        "                                n_mfcc=13)\n",
        "\n",
        "    # If the audio file is shorter than the max_sequence_length, pad it with zeros\n",
        "    if (max_sequence_length > mfcc.shape[1]):\n",
        "        pad_width = max_sequence_length - mfcc.shape[1]\n",
        "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "\n",
        "    # If the audio file is longer than the max_sequence_length, truncate it\n",
        "    elif (max_sequence_length < mfcc.shape[1]):\n",
        "        mfcc = mfcc[:, :max_sequence_length]\n",
        "\n",
        "    return mfcc\n",
        "\n",
        "def process_data(file_path):\n",
        "    # Load the CSV file\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Replace '/media/data/' with '/content/drive/MyDrive/assigment/' and remove '.wav' extension in 'file_name'\n",
        "    df['file_name'] = df['file_name'].str.replace('/media/data/', '/content/drive/MyDrive/assigment/').str.replace('.wav', '')\n",
        "\n",
        "    # Construct the full paths for the chunk files\n",
        "    full_paths = df.apply(lambda row: row['file_name'] + row['chunk_name'], axis=1)\n",
        "\n",
        "    # Get the labels from the 'affect' column\n",
        "    labels = df['affect'].values\n",
        "\n",
        "    # Encode the labels into integers\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(labels)\n",
        "\n",
        "    # Convert the integer labels into one-hot vectors\n",
        "    y = to_categorical(y)\n",
        "\n",
        "    # Initialize a dictionary to hold the MFCC features\n",
        "    mfccs_dict = {}\n",
        "\n",
        "    # Traverse through the full paths and extract MFCC features\n",
        "    for i, file_path in enumerate(full_paths):\n",
        "        # Extract MFCC features\n",
        "        mfccs = extract_mfcc(file_path, n_fft=2048, hop_length=512, max_sequence_length=500)\n",
        "\n",
        "        # Add the MFCC features to the dictionary\n",
        "        mfccs_dict[file_path] = (mfccs, y[i])\n",
        "\n",
        "    return mfccs_dict\n",
        "\n",
        "# Process the training and test data\n",
        "mfccs_train = process_data('/content/drive/MyDrive/assigment/filtered_training_data.csv')\n",
        "mfccs_test = process_data('/content/drive/MyDrive/assigment/test_data.csv')\n",
        "\n",
        "# Save the MFCC features to .npy files\n",
        "np.save('mfccs_train.npy', mfccs_train)\n",
        "np.save('mfccs_test.npy', mfccs_test)\n"
      ],
      "metadata": {
        "id": "p_8eqwh1nUzq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training the CNN model\n",
        "\n",
        "Next, we proceed to train our Convolutional Neural Network (CNN) model. We start by loading the previously saved MFCC features for the training and test data, in which the test data was extracted from the perceived emotion. The MFCC features and labels are then extracted and the training data is split into a training set and a validation set.\n",
        "\n",
        "We define our CRNN model using the Sequential API from Keras, with multiple layers including Conv2D, MaxPooling2D, Dropout, Flatten, Dense, and BatchNormalization. The model is compiled with a categorical crossentropy loss function and the Adam optimizer.\n",
        "\n",
        "The model is then trained on the training data for a specified number of epochs, with the validation data used for validation in each epoch. The trained model will then also be saved to a .keras file for future use. Finally, the model's performance is evaluated on the test data, with the accuracy and F1 score calculated and printed.\n",
        "\n",
        "To test with different hyperparameters, we run a for loop with 2x2 combinations of different batch size and epochs, resulted in 4 sets of different hyperparmeters."
      ],
      "metadata": {
        "id": "eibqrD5maVz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "\n",
        "# Load the MFCC features\n",
        "mfccs_train = np.load('mfccs_train.npy', allow_pickle=True).item()\n",
        "mfccs_test = np.load('mfccs_test.npy', allow_pickle=True).item()\n",
        "\n",
        "# Get the MFCC features and labels\n",
        "X_train = np.array([mfccs for mfccs, label in mfccs_train.values()])\n",
        "y_train = np.array([label for mfccs, label in mfccs_train.values()])\n",
        "\n",
        "X_test = np.array([mfccs for mfccs, label in mfccs_test.values()])\n",
        "y_test = np.array([label for mfccs, label in mfccs_test.values()])\n",
        "\n",
        "# Split the training data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=30)\n",
        "\n",
        "# Define the batch sizes and epochs\n",
        "batch_sizes = [32, 64]\n",
        "epochs_list = [30, 50]\n",
        "\n",
        "# Testing different batch size and number of epochs\n",
        "for batch_size in batch_sizes:\n",
        "    for epochs in epochs_list:\n",
        "        print(f\"\\nTraining model with batch size {batch_size} and {epochs} epochs\")\n",
        "\n",
        "        # Create a new instance of the model\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(13, 500, 1)))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.25))\n",
        "        model.add(Dense(y_train.shape[1], activation='softmax'))\n",
        "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "        # Train the model with the current batch size and number of epochs\n",
        "        model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "        # Evaluate the model\n",
        "        y_pred = model.predict(X_test)\n",
        "        accuracy = accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\n",
        "        f1 = f1_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), average='weighted')\n",
        "        print(f\"Accuracy with batch size {batch_size} and {epochs} epochs: {accuracy}\")\n",
        "        print(f\"F1 Score with batch size {batch_size} and {epochs} epochs: {f1}\\n\")\n",
        "\n",
        "        # If the batch size is 64 and the number of epochs is 50, save the model\n",
        "        if batch_size == 64 and epochs == 50:\n",
        "            model.save('cnn.keras')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toGnjvUS0rNx",
        "outputId": "ab3e9f98-193a-4d31-c257-ba9a66a9e555"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model with batch size 32 and 30 epochs\n",
            "Epoch 1/30\n",
            "74/74 [==============================] - 26s 325ms/step - loss: 5.8710 - accuracy: 0.1507 - val_loss: 5.1307 - val_accuracy: 0.1404\n",
            "Epoch 2/30\n",
            "74/74 [==============================] - 21s 291ms/step - loss: 4.7974 - accuracy: 0.1550 - val_loss: 4.1999 - val_accuracy: 0.1827\n",
            "Epoch 3/30\n",
            "74/74 [==============================] - 25s 336ms/step - loss: 4.3089 - accuracy: 0.1634 - val_loss: 3.8753 - val_accuracy: 0.1810\n",
            "Epoch 4/30\n",
            "74/74 [==============================] - 23s 318ms/step - loss: 3.9803 - accuracy: 0.1689 - val_loss: 3.6719 - val_accuracy: 0.1692\n",
            "Epoch 5/30\n",
            "74/74 [==============================] - 22s 293ms/step - loss: 3.7110 - accuracy: 0.1897 - val_loss: 3.5312 - val_accuracy: 0.1692\n",
            "Epoch 6/30\n",
            "74/74 [==============================] - 24s 322ms/step - loss: 3.5852 - accuracy: 0.1846 - val_loss: 3.4192 - val_accuracy: 0.1997\n",
            "Epoch 7/30\n",
            "74/74 [==============================] - 24s 318ms/step - loss: 3.4695 - accuracy: 0.1765 - val_loss: 3.3023 - val_accuracy: 0.2081\n",
            "Epoch 8/30\n",
            "74/74 [==============================] - 22s 300ms/step - loss: 3.3539 - accuracy: 0.1833 - val_loss: 3.2101 - val_accuracy: 0.1861\n",
            "Epoch 9/30\n",
            "74/74 [==============================] - 23s 318ms/step - loss: 3.2874 - accuracy: 0.1935 - val_loss: 3.2287 - val_accuracy: 0.1692\n",
            "Epoch 10/30\n",
            "74/74 [==============================] - 28s 380ms/step - loss: 3.1604 - accuracy: 0.1990 - val_loss: 3.1036 - val_accuracy: 0.1929\n",
            "Epoch 11/30\n",
            "74/74 [==============================] - 22s 296ms/step - loss: 3.0695 - accuracy: 0.2003 - val_loss: 3.0066 - val_accuracy: 0.2132\n",
            "Epoch 12/30\n",
            "74/74 [==============================] - 23s 317ms/step - loss: 2.9776 - accuracy: 0.2096 - val_loss: 2.9568 - val_accuracy: 0.1878\n",
            "Epoch 13/30\n",
            "74/74 [==============================] - 22s 295ms/step - loss: 2.9370 - accuracy: 0.2231 - val_loss: 2.9187 - val_accuracy: 0.2047\n",
            "Epoch 14/30\n",
            "74/74 [==============================] - 23s 317ms/step - loss: 2.9015 - accuracy: 0.2096 - val_loss: 2.8552 - val_accuracy: 0.2318\n",
            "Epoch 15/30\n",
            "74/74 [==============================] - 24s 320ms/step - loss: 2.8394 - accuracy: 0.2303 - val_loss: 2.8156 - val_accuracy: 0.2098\n",
            "Epoch 16/30\n",
            "74/74 [==============================] - 22s 299ms/step - loss: 2.7999 - accuracy: 0.2214 - val_loss: 2.8037 - val_accuracy: 0.1946\n",
            "Epoch 17/30\n",
            "74/74 [==============================] - 24s 320ms/step - loss: 2.7620 - accuracy: 0.2299 - val_loss: 2.8138 - val_accuracy: 0.2267\n",
            "Epoch 18/30\n",
            "74/74 [==============================] - 22s 293ms/step - loss: 2.7471 - accuracy: 0.2417 - val_loss: 3.0471 - val_accuracy: 0.1692\n",
            "Epoch 19/30\n",
            "74/74 [==============================] - 23s 312ms/step - loss: 2.9051 - accuracy: 0.2210 - val_loss: 3.0067 - val_accuracy: 0.1810\n",
            "Epoch 20/30\n",
            "74/74 [==============================] - 23s 307ms/step - loss: 2.7687 - accuracy: 0.2176 - val_loss: 2.9665 - val_accuracy: 0.1455\n",
            "Epoch 21/30\n",
            "74/74 [==============================] - 22s 297ms/step - loss: 2.6880 - accuracy: 0.2312 - val_loss: 2.6836 - val_accuracy: 0.2200\n",
            "Epoch 22/30\n",
            "74/74 [==============================] - 23s 314ms/step - loss: 2.6468 - accuracy: 0.2515 - val_loss: 2.7250 - val_accuracy: 0.2132\n",
            "Epoch 23/30\n",
            "74/74 [==============================] - 21s 289ms/step - loss: 2.6145 - accuracy: 0.2570 - val_loss: 2.6899 - val_accuracy: 0.2030\n",
            "Epoch 24/30\n",
            "74/74 [==============================] - 23s 317ms/step - loss: 2.6407 - accuracy: 0.2591 - val_loss: 2.8785 - val_accuracy: 0.1794\n",
            "Epoch 25/30\n",
            "74/74 [==============================] - 21s 289ms/step - loss: 2.6907 - accuracy: 0.2705 - val_loss: 2.8350 - val_accuracy: 0.2030\n",
            "Epoch 26/30\n",
            "74/74 [==============================] - 23s 318ms/step - loss: 2.6815 - accuracy: 0.2786 - val_loss: 2.7943 - val_accuracy: 0.2420\n",
            "Epoch 27/30\n",
            "74/74 [==============================] - 23s 312ms/step - loss: 2.7098 - accuracy: 0.2951 - val_loss: 3.0067 - val_accuracy: 0.2098\n",
            "Epoch 28/30\n",
            "74/74 [==============================] - 22s 293ms/step - loss: 2.7770 - accuracy: 0.2934 - val_loss: 3.1731 - val_accuracy: 0.2098\n",
            "Epoch 29/30\n",
            "74/74 [==============================] - 23s 314ms/step - loss: 2.7912 - accuracy: 0.3002 - val_loss: 3.1274 - val_accuracy: 0.1861\n",
            "Epoch 30/30\n",
            "74/74 [==============================] - 22s 295ms/step - loss: 2.7988 - accuracy: 0.3014 - val_loss: 2.9485 - val_accuracy: 0.2284\n",
            "4/4 [==============================] - 0s 46ms/step\n",
            "Accuracy with batch size 32 and 30 epochs: 0.27\n",
            "F1 Score with batch size 32 and 30 epochs: 0.22764981648203025\n",
            "\n",
            "\n",
            "Training model with batch size 32 and 50 epochs\n",
            "Epoch 1/50\n",
            "74/74 [==============================] - 26s 326ms/step - loss: 5.8436 - accuracy: 0.1520 - val_loss: 5.1868 - val_accuracy: 0.1404\n",
            "Epoch 2/50\n",
            "74/74 [==============================] - 24s 320ms/step - loss: 4.7533 - accuracy: 0.1571 - val_loss: 4.3010 - val_accuracy: 0.1404\n",
            "Epoch 3/50\n",
            "74/74 [==============================] - 22s 291ms/step - loss: 4.2156 - accuracy: 0.1740 - val_loss: 3.9116 - val_accuracy: 0.1557\n",
            "Epoch 4/50\n",
            "74/74 [==============================] - 24s 322ms/step - loss: 3.9246 - accuracy: 0.1575 - val_loss: 3.7602 - val_accuracy: 0.1743\n",
            "Epoch 5/50\n",
            "74/74 [==============================] - 23s 307ms/step - loss: 3.7160 - accuracy: 0.1494 - val_loss: 3.4060 - val_accuracy: 0.1777\n",
            "Epoch 6/50\n",
            "74/74 [==============================] - 23s 309ms/step - loss: 3.4772 - accuracy: 0.1672 - val_loss: 3.2629 - val_accuracy: 0.1794\n",
            "Epoch 7/50\n",
            "74/74 [==============================] - 24s 327ms/step - loss: 3.3163 - accuracy: 0.1617 - val_loss: 3.1412 - val_accuracy: 0.1675\n",
            "Epoch 8/50\n",
            "74/74 [==============================] - 22s 293ms/step - loss: 3.1841 - accuracy: 0.1600 - val_loss: 3.0550 - val_accuracy: 0.1709\n",
            "Epoch 9/50\n",
            "74/74 [==============================] - 24s 322ms/step - loss: 3.0653 - accuracy: 0.1931 - val_loss: 2.9385 - val_accuracy: 0.1912\n",
            "Epoch 10/50\n",
            "74/74 [==============================] - 23s 318ms/step - loss: 2.9801 - accuracy: 0.1867 - val_loss: 2.8851 - val_accuracy: 0.1912\n",
            "Epoch 11/50\n",
            "74/74 [==============================] - 22s 304ms/step - loss: 2.8936 - accuracy: 0.1774 - val_loss: 11.0620 - val_accuracy: 0.1269\n",
            "Epoch 12/50\n",
            "74/74 [==============================] - 24s 322ms/step - loss: 2.8388 - accuracy: 0.1867 - val_loss: 2.7858 - val_accuracy: 0.1810\n",
            "Epoch 13/50\n",
            "74/74 [==============================] - 23s 306ms/step - loss: 2.7721 - accuracy: 0.1977 - val_loss: 2.7665 - val_accuracy: 0.1743\n",
            "Epoch 14/50\n",
            "74/74 [==============================] - 23s 302ms/step - loss: 2.7362 - accuracy: 0.1867 - val_loss: 2.7447 - val_accuracy: 0.1861\n",
            "Epoch 15/50\n",
            "74/74 [==============================] - 24s 320ms/step - loss: 2.6416 - accuracy: 0.2096 - val_loss: 2.5940 - val_accuracy: 0.1946\n",
            "Epoch 16/50\n",
            "74/74 [==============================] - 21s 290ms/step - loss: 2.5977 - accuracy: 0.1986 - val_loss: 2.9498 - val_accuracy: 0.1861\n",
            "Epoch 17/50\n",
            "74/74 [==============================] - 23s 311ms/step - loss: 2.6539 - accuracy: 0.2130 - val_loss: 2.5858 - val_accuracy: 0.2115\n",
            "Epoch 18/50\n",
            "74/74 [==============================] - 23s 310ms/step - loss: 2.5661 - accuracy: 0.2159 - val_loss: 2.5661 - val_accuracy: 0.2047\n",
            "Epoch 19/50\n",
            "74/74 [==============================] - 22s 294ms/step - loss: 2.5425 - accuracy: 0.2223 - val_loss: 2.5662 - val_accuracy: 0.1912\n",
            "Epoch 20/50\n",
            "74/74 [==============================] - 23s 315ms/step - loss: 2.5279 - accuracy: 0.2159 - val_loss: 2.5308 - val_accuracy: 0.1912\n",
            "Epoch 21/50\n",
            "74/74 [==============================] - 21s 286ms/step - loss: 2.5214 - accuracy: 0.2223 - val_loss: 3.0429 - val_accuracy: 0.1658\n",
            "Epoch 22/50\n",
            "74/74 [==============================] - 23s 314ms/step - loss: 2.5706 - accuracy: 0.2345 - val_loss: 2.7143 - val_accuracy: 0.1743\n",
            "Epoch 23/50\n",
            "74/74 [==============================] - 24s 320ms/step - loss: 2.5275 - accuracy: 0.2231 - val_loss: 2.4956 - val_accuracy: 0.2217\n",
            "Epoch 24/50\n",
            "74/74 [==============================] - 22s 292ms/step - loss: 2.4691 - accuracy: 0.2434 - val_loss: 2.5318 - val_accuracy: 0.2014\n",
            "Epoch 25/50\n",
            "74/74 [==============================] - 24s 323ms/step - loss: 2.5030 - accuracy: 0.2345 - val_loss: 2.5562 - val_accuracy: 0.2098\n",
            "Epoch 26/50\n",
            "74/74 [==============================] - 23s 315ms/step - loss: 2.4704 - accuracy: 0.2405 - val_loss: 2.5300 - val_accuracy: 0.2183\n",
            "Epoch 27/50\n",
            "74/74 [==============================] - 22s 300ms/step - loss: 2.4527 - accuracy: 0.2574 - val_loss: 2.5612 - val_accuracy: 0.2047\n",
            "Epoch 28/50\n",
            "74/74 [==============================] - 24s 322ms/step - loss: 2.4611 - accuracy: 0.2570 - val_loss: 2.5832 - val_accuracy: 0.2234\n",
            "Epoch 29/50\n",
            "74/74 [==============================] - 23s 317ms/step - loss: 2.5790 - accuracy: 0.2633 - val_loss: 2.7507 - val_accuracy: 0.1760\n",
            "Epoch 30/50\n",
            "74/74 [==============================] - 23s 306ms/step - loss: 2.6547 - accuracy: 0.2705 - val_loss: 2.7747 - val_accuracy: 0.2200\n",
            "Epoch 31/50\n",
            "74/74 [==============================] - 24s 328ms/step - loss: 2.6089 - accuracy: 0.2790 - val_loss: 2.6764 - val_accuracy: 0.2098\n",
            "Epoch 32/50\n",
            "74/74 [==============================] - 24s 320ms/step - loss: 2.6327 - accuracy: 0.2633 - val_loss: 3.8151 - val_accuracy: 0.1455\n",
            "Epoch 33/50\n",
            "74/74 [==============================] - 23s 306ms/step - loss: 2.5982 - accuracy: 0.2477 - val_loss: 3.0261 - val_accuracy: 0.1523\n",
            "Epoch 34/50\n",
            "74/74 [==============================] - 23s 315ms/step - loss: 2.5980 - accuracy: 0.2354 - val_loss: 2.6795 - val_accuracy: 0.1844\n",
            "Epoch 35/50\n",
            "74/74 [==============================] - 23s 309ms/step - loss: 2.5566 - accuracy: 0.2286 - val_loss: 2.6038 - val_accuracy: 0.1963\n",
            "Epoch 36/50\n",
            "74/74 [==============================] - 22s 300ms/step - loss: 2.4862 - accuracy: 0.2663 - val_loss: 2.6671 - val_accuracy: 0.2250\n",
            "Epoch 37/50\n",
            "74/74 [==============================] - 24s 322ms/step - loss: 2.4831 - accuracy: 0.2633 - val_loss: 25.9598 - val_accuracy: 0.1421\n",
            "Epoch 38/50\n",
            "74/74 [==============================] - 23s 318ms/step - loss: 2.4858 - accuracy: 0.2718 - val_loss: 2.6015 - val_accuracy: 0.2081\n",
            "Epoch 39/50\n",
            "74/74 [==============================] - 23s 307ms/step - loss: 2.5108 - accuracy: 0.2866 - val_loss: 2.6368 - val_accuracy: 0.2217\n",
            "Epoch 40/50\n",
            "74/74 [==============================] - 23s 318ms/step - loss: 2.5115 - accuracy: 0.2896 - val_loss: 2.7983 - val_accuracy: 0.2115\n",
            "Epoch 41/50\n",
            "74/74 [==============================] - 22s 304ms/step - loss: 2.5788 - accuracy: 0.2777 - val_loss: 2.7806 - val_accuracy: 0.2217\n",
            "Epoch 42/50\n",
            "74/74 [==============================] - 22s 302ms/step - loss: 2.5988 - accuracy: 0.2921 - val_loss: 2.7807 - val_accuracy: 0.2149\n",
            "Epoch 43/50\n",
            "74/74 [==============================] - 24s 319ms/step - loss: 2.5737 - accuracy: 0.3167 - val_loss: 2.7284 - val_accuracy: 0.2132\n",
            "Epoch 44/50\n",
            "74/74 [==============================] - 21s 288ms/step - loss: 2.5716 - accuracy: 0.3235 - val_loss: 2.8790 - val_accuracy: 0.1929\n",
            "Epoch 45/50\n",
            "74/74 [==============================] - 24s 318ms/step - loss: 2.6552 - accuracy: 0.3044 - val_loss: 2.9096 - val_accuracy: 0.2064\n",
            "Epoch 46/50\n",
            "74/74 [==============================] - 24s 326ms/step - loss: 2.6101 - accuracy: 0.3061 - val_loss: 2.7668 - val_accuracy: 0.2200\n",
            "Epoch 47/50\n",
            "74/74 [==============================] - 22s 302ms/step - loss: 2.6180 - accuracy: 0.3332 - val_loss: 2.8359 - val_accuracy: 0.2572\n",
            "Epoch 48/50\n",
            "74/74 [==============================] - 24s 319ms/step - loss: 2.6629 - accuracy: 0.3256 - val_loss: 2.8385 - val_accuracy: 0.2589\n",
            "Epoch 49/50\n",
            "74/74 [==============================] - 23s 311ms/step - loss: 2.6276 - accuracy: 0.3421 - val_loss: 2.8377 - val_accuracy: 0.2420\n",
            "Epoch 50/50\n",
            "74/74 [==============================] - 21s 288ms/step - loss: 2.6300 - accuracy: 0.3527 - val_loss: 2.9106 - val_accuracy: 0.2267\n",
            "4/4 [==============================] - 0s 47ms/step\n",
            "Accuracy with batch size 32 and 50 epochs: 0.46\n",
            "F1 Score with batch size 32 and 50 epochs: 0.46442857142857136\n",
            "\n",
            "\n",
            "Training model with batch size 64 and 30 epochs\n",
            "Epoch 1/30\n",
            "37/37 [==============================] - 26s 655ms/step - loss: 6.0771 - accuracy: 0.1550 - val_loss: 7.0733 - val_accuracy: 0.1286\n",
            "Epoch 2/30\n",
            "37/37 [==============================] - 24s 648ms/step - loss: 5.1381 - accuracy: 0.1744 - val_loss: 4.7679 - val_accuracy: 0.1235\n",
            "Epoch 3/30\n",
            "37/37 [==============================] - 22s 607ms/step - loss: 4.5613 - accuracy: 0.1668 - val_loss: 4.1928 - val_accuracy: 0.1675\n",
            "Epoch 4/30\n",
            "37/37 [==============================] - 24s 632ms/step - loss: 4.1677 - accuracy: 0.1723 - val_loss: 4.0077 - val_accuracy: 0.1895\n",
            "Epoch 5/30\n",
            "37/37 [==============================] - 24s 640ms/step - loss: 3.9653 - accuracy: 0.1765 - val_loss: 3.7417 - val_accuracy: 0.2030\n",
            "Epoch 6/30\n",
            "37/37 [==============================] - 22s 602ms/step - loss: 3.7790 - accuracy: 0.1939 - val_loss: 3.5198 - val_accuracy: 0.2301\n",
            "Epoch 7/30\n",
            "37/37 [==============================] - 24s 645ms/step - loss: 3.6403 - accuracy: 0.1799 - val_loss: 3.4213 - val_accuracy: 0.2115\n",
            "Epoch 8/30\n",
            "37/37 [==============================] - 25s 672ms/step - loss: 3.4990 - accuracy: 0.1943 - val_loss: 3.3299 - val_accuracy: 0.2047\n",
            "Epoch 9/30\n",
            "37/37 [==============================] - 22s 598ms/step - loss: 3.3922 - accuracy: 0.2032 - val_loss: 3.3189 - val_accuracy: 0.1810\n",
            "Epoch 10/30\n",
            "37/37 [==============================] - 24s 641ms/step - loss: 3.3124 - accuracy: 0.2079 - val_loss: 3.2116 - val_accuracy: 0.2064\n",
            "Epoch 11/30\n",
            "37/37 [==============================] - 23s 637ms/step - loss: 3.2335 - accuracy: 0.2062 - val_loss: 3.1175 - val_accuracy: 0.2301\n",
            "Epoch 12/30\n",
            "37/37 [==============================] - 22s 591ms/step - loss: 3.1690 - accuracy: 0.2024 - val_loss: 3.0696 - val_accuracy: 0.2183\n",
            "Epoch 13/30\n",
            "37/37 [==============================] - 23s 635ms/step - loss: 3.1242 - accuracy: 0.2096 - val_loss: 3.1130 - val_accuracy: 0.2166\n",
            "Epoch 14/30\n",
            "37/37 [==============================] - 22s 607ms/step - loss: 3.0430 - accuracy: 0.2413 - val_loss: 3.0533 - val_accuracy: 0.2284\n",
            "Epoch 15/30\n",
            "37/37 [==============================] - 23s 609ms/step - loss: 2.9885 - accuracy: 0.2464 - val_loss: 3.0732 - val_accuracy: 0.2047\n",
            "Epoch 16/30\n",
            "37/37 [==============================] - 24s 646ms/step - loss: 2.9712 - accuracy: 0.2625 - val_loss: 3.1198 - val_accuracy: 0.2234\n",
            "Epoch 17/30\n",
            "37/37 [==============================] - 24s 650ms/step - loss: 3.0168 - accuracy: 0.2638 - val_loss: 3.1507 - val_accuracy: 0.2098\n",
            "Epoch 18/30\n",
            "37/37 [==============================] - 23s 628ms/step - loss: 2.9946 - accuracy: 0.2803 - val_loss: 3.6588 - val_accuracy: 0.1591\n",
            "Epoch 19/30\n",
            "37/37 [==============================] - 24s 643ms/step - loss: 3.0691 - accuracy: 0.2892 - val_loss: 3.3994 - val_accuracy: 0.1692\n",
            "Epoch 20/30\n",
            "37/37 [==============================] - 22s 590ms/step - loss: 3.0562 - accuracy: 0.2955 - val_loss: 3.3166 - val_accuracy: 0.1658\n",
            "Epoch 21/30\n",
            "37/37 [==============================] - 23s 631ms/step - loss: 2.9673 - accuracy: 0.3218 - val_loss: 3.3505 - val_accuracy: 0.1997\n",
            "Epoch 22/30\n",
            "37/37 [==============================] - 23s 629ms/step - loss: 2.9707 - accuracy: 0.3594 - val_loss: 3.3699 - val_accuracy: 0.2081\n",
            "Epoch 23/30\n",
            "37/37 [==============================] - 22s 590ms/step - loss: 3.0193 - accuracy: 0.3738 - val_loss: 3.3838 - val_accuracy: 0.2200\n",
            "Epoch 24/30\n",
            "37/37 [==============================] - 23s 633ms/step - loss: 3.0306 - accuracy: 0.3781 - val_loss: 3.6070 - val_accuracy: 0.1810\n",
            "Epoch 25/30\n",
            "37/37 [==============================] - 23s 626ms/step - loss: 2.9891 - accuracy: 0.3925 - val_loss: 3.4552 - val_accuracy: 0.2132\n",
            "Epoch 26/30\n",
            "37/37 [==============================] - 22s 594ms/step - loss: 2.9527 - accuracy: 0.4208 - val_loss: 3.4085 - val_accuracy: 0.2250\n",
            "Epoch 27/30\n",
            "37/37 [==============================] - 23s 633ms/step - loss: 3.0105 - accuracy: 0.4179 - val_loss: 3.6163 - val_accuracy: 0.2183\n",
            "Epoch 28/30\n",
            "37/37 [==============================] - 22s 591ms/step - loss: 3.0736 - accuracy: 0.4445 - val_loss: 3.5469 - val_accuracy: 0.2369\n",
            "Epoch 29/30\n",
            "37/37 [==============================] - 24s 650ms/step - loss: 2.9884 - accuracy: 0.4793 - val_loss: 3.8383 - val_accuracy: 0.1929\n",
            "Epoch 30/30\n",
            "37/37 [==============================] - 23s 635ms/step - loss: 3.0376 - accuracy: 0.4577 - val_loss: 3.7960 - val_accuracy: 0.2047\n",
            "4/4 [==============================] - 0s 45ms/step\n",
            "Accuracy with batch size 64 and 30 epochs: 0.32\n",
            "F1 Score with batch size 64 and 30 epochs: 0.28968673805219486\n",
            "\n",
            "\n",
            "Training model with batch size 64 and 50 epochs\n",
            "Epoch 1/50\n",
            "37/37 [==============================] - 26s 653ms/step - loss: 6.0257 - accuracy: 0.1389 - val_loss: 6.1706 - val_accuracy: 0.1218\n",
            "Epoch 2/50\n",
            "37/37 [==============================] - 23s 620ms/step - loss: 5.0781 - accuracy: 0.1634 - val_loss: 4.5632 - val_accuracy: 0.1201\n",
            "Epoch 3/50\n",
            "37/37 [==============================] - 24s 651ms/step - loss: 4.4705 - accuracy: 0.1579 - val_loss: 4.1391 - val_accuracy: 0.1472\n",
            "Epoch 4/50\n",
            "37/37 [==============================] - 23s 634ms/step - loss: 4.0810 - accuracy: 0.1808 - val_loss: 3.7585 - val_accuracy: 0.1523\n",
            "Epoch 5/50\n",
            "37/37 [==============================] - 23s 611ms/step - loss: 3.8398 - accuracy: 0.1753 - val_loss: 3.5255 - val_accuracy: 0.2318\n",
            "Epoch 6/50\n",
            "37/37 [==============================] - 24s 657ms/step - loss: 3.6610 - accuracy: 0.1710 - val_loss: 3.3914 - val_accuracy: 0.2014\n",
            "Epoch 7/50\n",
            "37/37 [==============================] - 23s 629ms/step - loss: 3.4952 - accuracy: 0.1799 - val_loss: 3.2759 - val_accuracy: 0.1997\n",
            "Epoch 8/50\n",
            "37/37 [==============================] - 23s 614ms/step - loss: 3.3625 - accuracy: 0.1871 - val_loss: 3.2795 - val_accuracy: 0.1658\n",
            "Epoch 9/50\n",
            "37/37 [==============================] - 24s 654ms/step - loss: 3.2578 - accuracy: 0.1884 - val_loss: 3.0963 - val_accuracy: 0.2115\n",
            "Epoch 10/50\n",
            "37/37 [==============================] - 24s 646ms/step - loss: 3.1555 - accuracy: 0.1931 - val_loss: 3.0342 - val_accuracy: 0.1929\n",
            "Epoch 11/50\n",
            "37/37 [==============================] - 23s 610ms/step - loss: 3.0982 - accuracy: 0.1931 - val_loss: 2.9959 - val_accuracy: 0.2081\n",
            "Epoch 12/50\n",
            "37/37 [==============================] - 24s 643ms/step - loss: 3.0070 - accuracy: 0.2146 - val_loss: 3.1410 - val_accuracy: 0.1997\n",
            "Epoch 13/50\n",
            "37/37 [==============================] - 23s 636ms/step - loss: 3.0284 - accuracy: 0.2066 - val_loss: 2.9621 - val_accuracy: 0.2149\n",
            "Epoch 14/50\n",
            "37/37 [==============================] - 23s 607ms/step - loss: 2.9982 - accuracy: 0.2155 - val_loss: 2.9435 - val_accuracy: 0.1675\n",
            "Epoch 15/50\n",
            "37/37 [==============================] - 24s 656ms/step - loss: 2.8809 - accuracy: 0.2206 - val_loss: 2.8928 - val_accuracy: 0.2047\n",
            "Epoch 16/50\n",
            "37/37 [==============================] - 23s 612ms/step - loss: 2.8605 - accuracy: 0.2269 - val_loss: 2.9904 - val_accuracy: 0.2064\n",
            "Epoch 17/50\n",
            "37/37 [==============================] - 22s 602ms/step - loss: 2.8475 - accuracy: 0.2392 - val_loss: 2.9340 - val_accuracy: 0.2217\n",
            "Epoch 18/50\n",
            "37/37 [==============================] - 23s 632ms/step - loss: 2.8150 - accuracy: 0.2460 - val_loss: 3.0377 - val_accuracy: 0.2030\n",
            "Epoch 19/50\n",
            "37/37 [==============================] - 22s 592ms/step - loss: 2.7707 - accuracy: 0.2659 - val_loss: 3.0431 - val_accuracy: 0.1709\n",
            "Epoch 20/50\n",
            "37/37 [==============================] - 24s 639ms/step - loss: 2.7924 - accuracy: 0.2722 - val_loss: 3.1373 - val_accuracy: 0.1523\n",
            "Epoch 21/50\n",
            "37/37 [==============================] - 24s 647ms/step - loss: 2.8046 - accuracy: 0.2917 - val_loss: 3.3237 - val_accuracy: 0.1878\n",
            "Epoch 22/50\n",
            "37/37 [==============================] - 22s 589ms/step - loss: 2.9279 - accuracy: 0.2748 - val_loss: 3.2523 - val_accuracy: 0.1929\n",
            "Epoch 23/50\n",
            "37/37 [==============================] - 23s 637ms/step - loss: 2.8807 - accuracy: 0.3048 - val_loss: 3.1554 - val_accuracy: 0.1980\n",
            "Epoch 24/50\n",
            "37/37 [==============================] - 22s 606ms/step - loss: 2.8748 - accuracy: 0.3137 - val_loss: 3.1941 - val_accuracy: 0.2234\n",
            "Epoch 25/50\n",
            "37/37 [==============================] - 23s 604ms/step - loss: 2.9493 - accuracy: 0.3222 - val_loss: 3.2253 - val_accuracy: 0.2166\n",
            "Epoch 26/50\n",
            "37/37 [==============================] - 23s 629ms/step - loss: 2.9660 - accuracy: 0.3328 - val_loss: 3.2103 - val_accuracy: 0.2234\n",
            "Epoch 27/50\n",
            "37/37 [==============================] - 22s 589ms/step - loss: 2.9720 - accuracy: 0.3400 - val_loss: 3.7278 - val_accuracy: 0.2217\n",
            "Epoch 28/50\n",
            "37/37 [==============================] - 24s 649ms/step - loss: 2.9070 - accuracy: 0.3599 - val_loss: 3.3522 - val_accuracy: 0.2098\n",
            "Epoch 29/50\n",
            "37/37 [==============================] - 24s 662ms/step - loss: 2.9134 - accuracy: 0.3662 - val_loss: 3.2981 - val_accuracy: 0.2200\n",
            "Epoch 30/50\n",
            "37/37 [==============================] - 22s 606ms/step - loss: 2.9277 - accuracy: 0.3950 - val_loss: 3.3250 - val_accuracy: 0.2487\n",
            "Epoch 31/50\n",
            "37/37 [==============================] - 24s 657ms/step - loss: 2.9430 - accuracy: 0.4035 - val_loss: 3.4189 - val_accuracy: 0.2437\n",
            "Epoch 32/50\n",
            "37/37 [==============================] - 25s 672ms/step - loss: 2.8760 - accuracy: 0.4340 - val_loss: 3.4516 - val_accuracy: 0.2606\n",
            "Epoch 33/50\n",
            "37/37 [==============================] - 22s 598ms/step - loss: 2.9050 - accuracy: 0.4386 - val_loss: 3.8341 - val_accuracy: 0.2183\n",
            "Epoch 34/50\n",
            "37/37 [==============================] - 24s 628ms/step - loss: 2.9005 - accuracy: 0.4517 - val_loss: 3.7314 - val_accuracy: 0.2453\n",
            "Epoch 35/50\n",
            "37/37 [==============================] - 24s 644ms/step - loss: 2.9368 - accuracy: 0.4691 - val_loss: 3.5058 - val_accuracy: 0.2538\n",
            "Epoch 36/50\n",
            "37/37 [==============================] - 22s 597ms/step - loss: 2.8929 - accuracy: 0.4852 - val_loss: 3.6635 - val_accuracy: 0.2437\n",
            "Epoch 37/50\n",
            "37/37 [==============================] - 24s 643ms/step - loss: 2.9076 - accuracy: 0.5021 - val_loss: 3.6704 - val_accuracy: 0.2487\n",
            "Epoch 38/50\n",
            "37/37 [==============================] - 24s 648ms/step - loss: 3.0456 - accuracy: 0.4691 - val_loss: 3.7784 - val_accuracy: 0.2318\n",
            "Epoch 39/50\n",
            "37/37 [==============================] - 24s 639ms/step - loss: 3.0481 - accuracy: 0.4983 - val_loss: 3.6832 - val_accuracy: 0.2386\n",
            "Epoch 40/50\n",
            "37/37 [==============================] - 24s 633ms/step - loss: 2.9940 - accuracy: 0.5157 - val_loss: 3.7080 - val_accuracy: 0.2437\n",
            "Epoch 41/50\n",
            "37/37 [==============================] - 24s 648ms/step - loss: 2.9751 - accuracy: 0.5343 - val_loss: 3.6955 - val_accuracy: 0.2453\n",
            "Epoch 42/50\n",
            "37/37 [==============================] - 22s 598ms/step - loss: 2.9328 - accuracy: 0.5373 - val_loss: 3.7924 - val_accuracy: 0.2166\n",
            "Epoch 43/50\n",
            "37/37 [==============================] - 23s 634ms/step - loss: 2.9086 - accuracy: 0.5495 - val_loss: 3.8442 - val_accuracy: 0.2386\n",
            "Epoch 44/50\n",
            "37/37 [==============================] - 23s 633ms/step - loss: 2.9678 - accuracy: 0.5682 - val_loss: 3.8819 - val_accuracy: 0.2301\n",
            "Epoch 45/50\n",
            "37/37 [==============================] - 23s 602ms/step - loss: 2.9700 - accuracy: 0.5737 - val_loss: 3.9581 - val_accuracy: 0.2234\n",
            "Epoch 46/50\n",
            "37/37 [==============================] - 24s 646ms/step - loss: 2.9902 - accuracy: 0.5741 - val_loss: 3.9601 - val_accuracy: 0.2555\n",
            "Epoch 47/50\n",
            "37/37 [==============================] - 23s 617ms/step - loss: 2.9926 - accuracy: 0.5720 - val_loss: 3.9423 - val_accuracy: 0.2606\n",
            "Epoch 48/50\n",
            "37/37 [==============================] - 23s 607ms/step - loss: 3.0518 - accuracy: 0.5855 - val_loss: 3.9805 - val_accuracy: 0.2420\n",
            "Epoch 49/50\n",
            "37/37 [==============================] - 24s 653ms/step - loss: 2.9583 - accuracy: 0.6143 - val_loss: 4.1597 - val_accuracy: 0.2149\n",
            "Epoch 50/50\n",
            "37/37 [==============================] - 23s 637ms/step - loss: 3.0311 - accuracy: 0.6037 - val_loss: 4.1694 - val_accuracy: 0.2234\n",
            "4/4 [==============================] - 1s 79ms/step\n",
            "Accuracy with batch size 64 and 50 epochs: 0.57\n",
            "F1 Score with batch size 64 and 50 epochs: 0.5603118393234672\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From all results of different hyperparameters sets, the results indicate that the model’s performance improved over time. Here are some key observations\n",
        "\n",
        "\n",
        "*   In the initial epochs, the model had a relatively low accuracy on both the training and validation sets. However, as the training progressed, the model’s accuracy improved. However, the validation accuracy fluctuated during these epochs, suggest that we are overfitting our CNN model. If we used a smaller batch size, the result tends to have a lower validation loss but noticable smaller accuracy.\n",
        "*   After training, the model was evaluated on the test set. On the latest run with 50 epochs and batch size of 64, It achieved an accuracy of 57% and an F1 score of approximately 0.56, indicating that choosing bigger number yields better accuracy.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wMakq6rTe2GO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing with train_test_split data\n",
        "On our last section of the notebook, the trained model was evaluated on a test set that was directly split from the filtered_training_data.csv.\n",
        "\n",
        "On our latest run, The model achieved an accuracy of approximately 0.716 and an F1 score of approximately 0.719 on the test set. These metrics indicate that the model was able to correctly predict the emotion labels of the test data with a high degree of accuracy. The F1 score, also suggests that the model has a balanced performance in terms of both false positives and false negatives. Since it was tested on unseen data that was not used during the training process,the results also suggest that the model has learned to generalize well from the training data and can make accurate predictions on new, unseen data.\n"
      ],
      "metadata": {
        "id": "QtYZ0boKuUsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from keras.models  import load_model\n",
        "\n",
        "# Load the MFCC features\n",
        "mfccs_data = process_data('/content/drive/MyDrive/assigment/filtered_training_data.csv')\n",
        "\n",
        "# Get the MFCC features and labels\n",
        "X = np.array([mfccs for mfccs, label in mfccs_data.values()])\n",
        "y = np.array([label for mfccs, label in mfccs_data.values()])\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load the trained model\n",
        "model_splittest = load_model('cnn.keras')\n",
        "\n",
        "# Reshape the test data\n",
        "X_test = X_test.reshape(X_test.shape[0], 13, 500, 1)\n",
        "\n",
        "# Evaluate the model with the test set\n",
        "y_pred = model_splittest.predict(X_test)\n",
        "accuracy = accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\n",
        "f1 = f1_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), average='weighted')\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "# Convert predicted probabilities to labels\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Display confusion matrix\n",
        "conf_matrix = confusion_matrix(np.argmax(y_test, axis=1), y_pred_labels)\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)\n",
        "\n",
        "# Print classification report\n",
        "print('Classification Report:')\n",
        "print(classification_report(np.argmax(y_test, axis=1), y_pred_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8ciTQqJv3zk",
        "outputId": "13f55280-2b23-40fb-8391-e04bce0a7dad"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 2s 82ms/step\n",
            "Accuracy: 0.7157360406091371\n",
            "F1 Score: 0.718704706867617\n",
            "Confusion Matrix:\n",
            "[[71  5  0  3  1  1  3]\n",
            " [13 49  1  2  2  8  4]\n",
            " [ 9  4 65  4  1  5  4]\n",
            " [10  1  0 71  0  5  1]\n",
            " [17  9  3  3 40  3  2]\n",
            " [11  0  4  5  1 56  1]\n",
            " [11  0  4  5  1  1 71]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.85      0.63        84\n",
            "           1       0.72      0.62      0.67        79\n",
            "           2       0.84      0.71      0.77        92\n",
            "           3       0.76      0.81      0.78        88\n",
            "           4       0.87      0.52      0.65        77\n",
            "           5       0.71      0.72      0.71        78\n",
            "           6       0.83      0.76      0.79        93\n",
            "\n",
            "    accuracy                           0.72       591\n",
            "   macro avg       0.75      0.71      0.72       591\n",
            "weighted avg       0.75      0.72      0.72       591\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing with the label only\n",
        "\n",
        "Following the mfcc test result, we also implemented a test for our model directly to the perceived emotion column label from our own csv dataset. Here are the keys factors drawn from the result\n",
        "\n",
        "*   Accuracy and F1 Score: The model achieved an accuracy of 0.32 on the test data. This means that the model correctly predicted the perceived emotion for 32% of the test samples. The weighted average F1 score is 0.31. Since The F1 score is a measure of a test’s accuracy that considers both the precision and the recall, hence we can see that it performs below average on the labels itself.\n",
        "*   Confusion Matrix: Showing how correct the model can predict in details. For example, we see that the model correctly predicted the emotion for the first emotion 12 times, but also misclassified it as class 1 four times, class 2 three times, and so on.\n",
        "*   Classification Report:For class 0, the model has a precision of 0.43, recall of 0.44, and F1-score of 0.44. This means that when the model predicts class 0, it is correct 43% of the time. Additionally, the model correctly identifies 44% of all actual instances of class 0.\n",
        "\n",
        "From these results, we can conclude that the model performs significantly better on the MFCC test compared to the label test. This suggests that the MFCC features provide important information for emotion prediction that is not captured by the labels alone. Therefore, using MFCC features for training our model could lead to better performance"
      ],
      "metadata": {
        "id": "d4b-5krJEiBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "model = load_model('cnn.keras')\n",
        "\n",
        "# Load the test data\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/assigment/test_data.csv\")\n",
        "\n",
        "# Assuming `labels` is your list of labels\n",
        "labels = df['perceived emotion'].values  # replace this with your actual labels\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(labels)\n",
        "\n",
        "# Prepare the test features\n",
        "X_test = np.array([mfccs for mfccs, label in mfccs_test.values()])\n",
        "\n",
        "# Convert predicted probabilities to labels to test\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "# Evaluate against 'perceived emotions'\n",
        "perceived_emotions = df['perceived emotion']\n",
        "perceived_emotions = label_encoder.transform(perceived_emotions)\n",
        "\n",
        "# Get f1 score and accuracy\n",
        "f1 = f1_score(perceived_emotions, y_pred, average='weighted')\n",
        "accuracy = accuracy_score(perceived_emotions, y_pred)\n",
        "print(f'F1 Score for Perceived Emotions on CNN: {f1}')\n",
        "print(f'Accuracy for Perceived Emotions on CNN: {accuracy}')\n",
        "\n",
        "# Display confusion matrix\n",
        "conf_matrix = confusion_matrix(perceived_emotions, y_pred)\n",
        "print('Confusion Matrix for Perceived Emotions on CNN:')\n",
        "print(conf_matrix)\n",
        "\n",
        "# Show classification report\n",
        "print('Classification Report for Perceived Emotions on CNN:')\n",
        "print(classification_report(perceived_emotions, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_2HbxOX3Nbx",
        "outputId": "13a8b52c-52d6-42f1-e940-7c33e252ed5e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 72ms/step\n",
            "F1 Score for Perceived Emotions on CNN: 0.31068235694124646\n",
            "Accuracy for Perceived Emotions on CNN: 0.32\n",
            "Confusion Matrix for Perceived Emotions on CNN:\n",
            "[[12  4  3  6  0  2  0]\n",
            " [ 3  2  1  0  0  1  2]\n",
            " [ 3  0  5  0  0  0  1]\n",
            " [ 0  0  2  2  0  1  3]\n",
            " [ 3  1  4  2  2  5  2]\n",
            " [ 4  0  1  0  1  4  0]\n",
            " [ 3  1  2  5  1  1  5]]\n",
            "Classification Report for Perceived Emotions on CNN:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.44      0.44        27\n",
            "           1       0.25      0.22      0.24         9\n",
            "           2       0.28      0.56      0.37         9\n",
            "           3       0.13      0.25      0.17         8\n",
            "           4       0.50      0.11      0.17        19\n",
            "           5       0.29      0.40      0.33        10\n",
            "           6       0.38      0.28      0.32        18\n",
            "\n",
            "    accuracy                           0.32       100\n",
            "   macro avg       0.32      0.32      0.29       100\n",
            "weighted avg       0.37      0.32      0.31       100\n",
            "\n"
          ]
        }
      ]
    }
  ]
}